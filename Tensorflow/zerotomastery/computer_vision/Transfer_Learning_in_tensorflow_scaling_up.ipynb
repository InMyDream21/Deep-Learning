{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "B0lDWaCje_Tc",
        "4W1mf6lKlB8r",
        "41TlijSWpzfC",
        "PzTm4xyVt3iX",
        "2r_ko_NJymAX",
        "wlRsRHzB0AI6",
        "9YHK-ai43xEQ",
        "adCRw2EE91DB",
        "NK36KIVRG-ja"
      ],
      "mount_file_id": "12kZP49unmD2WbDytVBZOgsm0alTbdYUg",
      "authorship_tag": "ABX9TyN1DSySNizC4h3vIQs2brYb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/InMyDream21/Deep-Learning/blob/main/Tensorflow/zerotomastery/computer_vision/Transfer_Learning_in_tensorflow_scaling_up.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning with TensorFlow: Scaling up (Food Vision Mini)\n",
        "\n",
        "Weve seen the power of transfer learning feature extraction and fine-tuning, now its time to scale up to all of the classes in Food101 (101 classes).\n",
        "\n",
        "Our goal is to beat the original Food101 paper with 10% of the training (leveraging the power of deep learning)."
      ],
      "metadata": {
        "id": "Ue1tump7SCXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHeck to see if were using a gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIeaVyxdTbOq",
        "outputId": "00692dfc-887a-4a13-8344-06ac99bc41b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 19 12:57:23 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "In previous notebooks, weve created a series of helper functions to do different taks, lets download them."
      ],
      "metadata": {
        "id": "2PZDfPBSTvE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sci2cP2-T_I7",
        "outputId": "74a967a1-0b86-42ce-a2d2-39c893de2fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-19 12:57:24--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-19 12:57:24 (96.9 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for our notebook\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir"
      ],
      "metadata": {
        "id": "8bgWZeopUIIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 101 Food classes: working with less data\n",
        "\n",
        "our goal is to beat the original Food101 paper with 10% of the training data, so lets download it."
      ],
      "metadata": {
        "id": "sC9bTSLpUaN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
        "unzip_data(\"101_food_classes_10_percent.zip\")\n",
        "\n",
        "train_dir = \"101_food_classes_10_percent/train/\"\n",
        "test_dir = \"101_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLj_cpKRUh0U",
        "outputId": "c49f6f80-15f6-4ad7-f6d3-25c3de2c5301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-19 12:57:26--  https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 74.125.195.128, 142.250.107.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1625420029 (1.5G) [application/zip]\n",
            "Saving to: ‘101_food_classes_10_percent.zip’\n",
            "\n",
            "101_food_classes_10 100%[===================>]   1.51G   174MB/s    in 6.9s    \n",
            "\n",
            "2022-01-19 12:57:33 (225 MB/s) - ‘101_food_classes_10_percent.zip’ saved [1625420029/1625420029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images/classes are there?\n",
        "walk_through_dir(\"101_food_classes_10_percent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOFftgJPU5LY",
        "outputId": "0ba1188f-d2ae-4e84-fb4b-d737f3f97fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '101_food_classes_10_percent'.\n",
            "There are 101 directories and 0 images in '101_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/peking_duck'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bibimbap'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cup_cakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/macaroni_and_cheese'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_toast'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/baklava'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tuna_tartare'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/escargots'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/apple_pie'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chocolate_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hummus'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/clam_chowder'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/seaweed_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pad_thai'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/caesar_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lasagna'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spring_rolls'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ceviche'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cheese_plate'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/macarons'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beignets'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tacos'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/croque_madame'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/shrimp_and_grits'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/guacamole'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/panna_cotta'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/donuts'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/sashimi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/huevos_rancheros'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beet_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bread_pudding'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spaghetti_carbonara'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/dumplings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/risotto'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/foie_gras'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hot_and_sour_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cannoli'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/carrot_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/cheesecake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fried_calamari'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/paella'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_quesadilla'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/breakfast_burrito'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/prime_rib'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/creme_brulee'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/tiramisu'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/samosa'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beef_carpaccio'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/filet_mignon'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/takoyaki'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/red_velvet_cake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pork_chop'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/gnocchi'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/falafel'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/bruschetta'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/fish_and_chips'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/beef_tartare'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/baby_back_ribs'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/crab_cakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/eggs_benedict'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/spaghetti_bolognese'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_fries'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/deviled_eggs'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lobster_roll_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pho'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/club_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/poutine'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/miso_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/edamame'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/gyoza'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/grilled_cheese_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/omelette'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/nachos'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/french_onion_soup'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/caprese_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/strawberry_shortcake'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pancakes'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pulled_pork_sandwich'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ravioli'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/onion_rings'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/waffles'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/garlic_bread'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/hot_dog'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/churros'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/lobster_bisque'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/frozen_yogurt'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/mussels'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/greek_salad'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/chocolate_mousse'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/oysters'.\n",
            "There are 0 directories and 75 images in '101_food_classes_10_percent/train/scallops'.\n",
            "There are 101 directories and 0 images in '101_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/peking_duck'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bibimbap'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cup_cakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/macaroni_and_cheese'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_toast'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/baklava'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tuna_tartare'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/escargots'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/apple_pie'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chocolate_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hummus'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/clam_chowder'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/seaweed_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pad_thai'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/caesar_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lasagna'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spring_rolls'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ceviche'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cheese_plate'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/macarons'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beignets'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tacos'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/croque_madame'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/shrimp_and_grits'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/guacamole'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/panna_cotta'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/donuts'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/sashimi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/huevos_rancheros'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beet_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bread_pudding'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spaghetti_carbonara'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/dumplings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/risotto'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/foie_gras'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hot_and_sour_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cannoli'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/carrot_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/cheesecake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fried_calamari'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/paella'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_quesadilla'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/breakfast_burrito'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/prime_rib'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/creme_brulee'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/tiramisu'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/samosa'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beef_carpaccio'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/filet_mignon'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/takoyaki'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/red_velvet_cake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pork_chop'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/gnocchi'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/falafel'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/bruschetta'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/fish_and_chips'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/beef_tartare'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/baby_back_ribs'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/crab_cakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/eggs_benedict'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/spaghetti_bolognese'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_fries'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/deviled_eggs'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lobster_roll_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pho'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/club_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/poutine'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/miso_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/edamame'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/gyoza'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/grilled_cheese_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/omelette'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/nachos'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/french_onion_soup'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/caprese_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/strawberry_shortcake'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pancakes'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pulled_pork_sandwich'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ravioli'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/onion_rings'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/waffles'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/garlic_bread'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/hot_dog'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/churros'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/lobster_bisque'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/frozen_yogurt'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/mussels'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/greek_salad'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/chocolate_mousse'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/oysters'.\n",
            "There are 0 directories and 250 images in '101_food_classes_10_percent/test/scallops'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "train_data_all_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                                label_mode = \"categorical\",\n",
        "                                                                                image_size = IMG_SIZE)\n",
        "\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                label_mode = \"categorical\",\n",
        "                                                                image_size = IMG_SIZE,\n",
        "                                                                shuffle = False) # Dont shuffle test data for prediction analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ_MmDlJVE2A",
        "outputId": "ff1fb21b-ae5b-4917-f369-8fc655502ef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7575 files belonging to 101 classes.\n",
            "Found 25250 files belonging to 101 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a big dog model with transfer learning on 10% of 101 food classes\n",
        "\n",
        "Here are the steps we're going to take:\n",
        "* Create a ModelCheckpoint callback\n",
        "* Create a data augmentation layer to build data augmentation right into the model\n",
        "* Build a headless (no top layers) functional EfficientNetB0 backboned-model (we'll create our own output layer)\n",
        "* Compile our model\n",
        "* Feature extract for 5 full passes (5 epochs on the train dataset and validate on 15% of the test data to save epoch time)"
      ],
      "metadata": {
        "id": "LvOlaMmjV5ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create checkpoint callback\n",
        "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only = True,\n",
        "                                                         monitor = \"val_accuracy\",\n",
        "                                                         save_best_only = True)"
      ],
      "metadata": {
        "id": "4IqjgDj2WrD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data augmentation layer to incorporate it right into the model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Setup data augmentation \n",
        "data_augmentation = Sequential([\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\n",
        "  preprocessing.RandomRotation(0.2),\n",
        "  preprocessing.RandomHeight(0.2),\n",
        "  preprocessing.RandomWidth(0.2),\n",
        "  preprocessing.RandomZoom(0.2)\n",
        "], name = \"data_augmentation\")"
      ],
      "metadata": {
        "id": "x9ZEN45-XSp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the base model and freeze its layers (this will extract features)\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Setup model architecture with trainable top layers\n",
        "inputs = layers.Input(shape = (224, 224, 3), name = \"input_layer\")\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x, training = False)\n",
        "x = layers.GlobalAveragePooling2D(name = \"global_avg_pool\")(x)\n",
        "outputs = layers.Dense(len(train_data_all_10_percent.class_names), activation = \"softmax\", name = \"output_layer\")(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "ke2HXcUuYYWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d1a76a0-a912-4500-da6a-46efd4163212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "16719872/16705208 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of model we've created\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUh5Nl8EbFPB",
        "outputId": "ed52b1e1-4a77-423f-cc21-c08827d828d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "data_augmentation (Sequentia (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_avg_pool (GlobalAvera (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 101)               129381    \n",
            "=================================================================\n",
            "Total params: 4,178,952\n",
            "Trainable params: 129,381\n",
            "Non-trainable params: 4,049,571\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "all_classes_10_percent_history = model.fit(train_data_all_10_percent,\n",
        "                                           epochs = 5,\n",
        "                                           validation_data = test_data,\n",
        "                                           validation_steps = int(0.15 * len(test_data)),\n",
        "                                           callbacks = [checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DWDv-WwsbiO1",
        "outputId": "21ee93e8-df1e-4059-9c8e-1836630524fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a2f6a657aca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                            \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                            \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                            callbacks = [checkpoint_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model/efficientnetb0/stem_conv/Conv2D (defined at <ipython-input-12-a2f6a657aca8>:11) ]] [Op:__inference_train_function_15326]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the whole test dataset\n",
        "feature_extraction_results = model.evaluate(test_data)\n",
        "feature_extraction_results"
      ],
      "metadata": {
        "id": "ocIqGTAIcacf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(all_classes_10_percent_history)"
      ],
      "metadata": {
        "id": "pUuKX7sReX7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Question:** What do these curves suggest? Hint: Ideally the two curves should be very simmilar to each other, if not...\n",
        "\n",
        "Yeah its Overfitting..."
      ],
      "metadata": {
        "id": "DixvYARgfDdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "B0lDWaCje_Tc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the layer\n",
        "base_model.trainable = True\n",
        "\n",
        "# Refreeze every layer except the last 5\n",
        "for layer in base_model.layers[:-5]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "g9UVFVs3fs_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recompile\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "V8rXiC7LgFrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What layers in the model are trainable?\n",
        "for layer in model.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "oaZ_dmLqgkeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer_number, layer in enumerate(model.layers[2].layers):\n",
        "  print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "JNXp-Q0hgpWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune for 5 more epochs\n",
        "fine_tune_epochs = 10 # Model has already done 5 epochs (feature extraction), this is the total number of epochs we're after (5 + 5)\n",
        "\n",
        "# Fine-tune our model\n",
        "all_classes_10_percent_fine_tune_history = model.fit(train_data_all_10_percent,\n",
        "                                                     epochs = fine_tune_epochs,\n",
        "                                                     validation_data = test_data,\n",
        "                                                     validation_steps = int(0.15 * len(test_data)),\n",
        "                                                     initial_epoch = all_classes_10_percent_history.epoch[-1])"
      ],
      "metadata": {
        "id": "1H-JYOz4g7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the whole test data\n",
        "all_classes_10_percent_fine_tune_results = model.evaluate(test_data)\n",
        "all_classes_10_percent_fine_tune_results"
      ],
      "metadata": {
        "id": "BpCX6OFAi1hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the histories of feature extraction model with fine tuning model\n",
        "compare_historys(all_classes_10_percent_history,\n",
        "                 all_classes_10_percent_fine_tune_history,\n",
        "                 5)"
      ],
      "metadata": {
        "id": "8e7AfhDTkJkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and loading our model\n",
        "\n",
        "To use our model in an external application, we'll need to save it and export it somewhere"
      ],
      "metadata": {
        "id": "4W1mf6lKlB8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save our fine-tuned model\n",
        "model.save(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")"
      ],
      "metadata": {
        "id": "FqVoaeY7lpry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = tf.keras.models.load_model(\"drive/MyDrive/tensorflow_course/101_food_classes_10_percent_saved_big_dog_model\")"
      ],
      "metadata": {
        "id": "ajL1sR5qjrE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model and compare performance to pre saved model\n",
        "loaded_model_results = loaded_model.evaluate(test_data)\n",
        "loaded_model_results"
      ],
      "metadata": {
        "id": "byQ9leSGpZM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_classes_10_percent_fine_tune_results"
      ],
      "metadata": {
        "id": "pL8w9gmnpj9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the performance of the big dog model across all different classes\n",
        "\n",
        "Lets make some predictions, visualize them and then later find out which predictions were the \"most\" wrong"
      ],
      "metadata": {
        "id": "41TlijSWpzfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download pre-trained model\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip"
      ],
      "metadata": {
        "id": "Ah8ojzl_s9sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(\"06_101_food_class_10_percent_saved_big_dog_model.zip\")"
      ],
      "metadata": {
        "id": "_UwNkLMmtH0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in saved model\n",
        "model = tf.keras.models.load_model(\"06_101_food_class_10_percent_saved_big_dog_model\")"
      ],
      "metadata": {
        "id": "GLoNJCpstQpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model (the one we just downloaded on test data)\n",
        "results_downloaded_model = model.evaluate(test_data)\n",
        "results_downloaded_model"
      ],
      "metadata": {
        "id": "SIV7VCtxtidS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making predictions with out trained model"
      ],
      "metadata": {
        "id": "PzTm4xyVt3iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model\n",
        "preds_probs = model.predict(test_data, verbose = 1)"
      ],
      "metadata": {
        "id": "klKh50G4uXez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many predictions are there?\n",
        "len(preds_probs)"
      ],
      "metadata": {
        "id": "N4xkJyFWuy3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Whats the shape of our predictions\n",
        "preds_probs.shape"
      ],
      "metadata": {
        "id": "mwJZc6W6veks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see what the first 10 predictions look like\n",
        "preds_probs[:10]"
      ],
      "metadata": {
        "id": "51NzNMUMvpVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the first prediction probability array look like\n",
        "preds_probs[0], len(preds_probs[0]), sum(preds_probs[0])"
      ],
      "metadata": {
        "id": "TdvgdNUfv4On"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model outputs a prediction probability array (with N number of variables, where N is the number of classes) for each sample passed to the predict method"
      ],
      "metadata": {
        "id": "bxPKTH6rwA2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We get one prediction probability per lass (in our case theres 101 prediction probabilities)\n",
        "print(f\"Number of predictions probabilities for sample 0: {len(preds_probs[0])}\")\n",
        "print(f\"What prediction probability sample 0 looks like:\\n {preds_probs[0]}\")\n",
        "print(f\"The class with the highest probability by the model for sample 0: {preds_probs[0].argmax()}\")"
      ],
      "metadata": {
        "id": "yvo_haYhwcdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the pred classes of each label\n",
        "pred_classes = preds_probs.argmax(axis = 1)\n",
        "\n",
        "# How do they look?\n",
        "pred_classes[:10]"
      ],
      "metadata": {
        "id": "GoFBy1N2w97s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many pred classes do we have?\n",
        "len(pred_classes)"
      ],
      "metadata": {
        "id": "Mxc_dMsDxEHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got predictions array of all of our model's perdictions, to evaluate them, we need to compare them to the original test dataset labels."
      ],
      "metadata": {
        "id": "cCcWp8DOxWdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To get our test labels we need to unravel out test data batchdataset\n",
        "y_labels = []\n",
        "for images, labels in test_data.unbatch():\n",
        "  y_labels.append(labels.numpy().argmax())\n",
        "\n",
        "y_labels[:10]"
      ],
      "metadata": {
        "id": "_9k2WvefxreQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many y_labels are there?\n",
        "len(y_labels)"
      ],
      "metadata": {
        "id": "342ZUJO-yWsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating our model's predictions\n",
        "\n",
        "One way to check that our model's predictions array is in the same order as our test labels array is to find the accuracy score.\n"
      ],
      "metadata": {
        "id": "2r_ko_NJymAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_downloaded_model"
      ],
      "metadata": {
        "id": "K8GCecDczLd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets try scikit-learn's accuracy score function and see what it comes up with\n",
        "from sklearn.metrics import accuracy_score\n",
        "sklearn_accuracy = accuracy_score(y_labels,\n",
        "                                  pred_classes)\n",
        "sklearn_accuracy"
      ],
      "metadata": {
        "id": "1QJejqdUzNn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Does this metric come close to our model's evaluate results\n",
        "import numpy as np\n",
        "np.isclose(sklearn_accuracy, results_downloaded_model[1])"
      ],
      "metadata": {
        "id": "qsQFM1Eszz95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets get visual: Making a Confusion Matrix"
      ],
      "metadata": {
        "id": "wlRsRHzB0AI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import make_confusion_matrix"
      ],
      "metadata": {
        "id": "4iNGjZ9O3NdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a list of class names\n",
        "class_names = test_data.class_names"
      ],
      "metadata": {
        "id": "g-mS83FA3fYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# We need to make some changes to our make_confusion_matrix function to ensure the x-labels print vertically\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  ### Changed (plot x-labels verically) ###\n",
        "  plt.xticks(rotation = 70, fontsize = text_size)\n",
        "  plt.yticks(fontsize = text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")"
      ],
      "metadata": {
        "id": "rDtllf714ZWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_confusion_matrix(y_true = y_labels,\n",
        "                      y_pred = pred_classes,\n",
        "                      classes = class_names,\n",
        "                      figsize = (100, 100),\n",
        "                      text_size = 20,\n",
        "                      savefig = True)"
      ],
      "metadata": {
        "id": "SUAY9w5t3ZFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets keep the evaluation train going, time for a classification report\n",
        "\n",
        "Scikit-learn has a helpful function for acquiring many different classification metrics per class(e.g. precision, recall and F1) called classification_report"
      ],
      "metadata": {
        "id": "9YHK-ai43xEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true = y_labels,\n",
        "                            y_pred = pred_classes))"
      ],
      "metadata": {
        "id": "wN66heCR6G3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The numbers above give a great class-by-class evaluation of our model's predictions but with so many classes, theyre quite hard to understand.\n",
        "\n",
        "How about we create a visualization to get a better understanding?"
      ],
      "metadata": {
        "id": "dhHogfp_7AOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a dictionary of the classification report\n",
        "classification_report_dict = classification_report(y_labels, pred_classes, output_dict = True)\n",
        "classification_report_dict"
      ],
      "metadata": {
        "id": "S-xg_olX6RTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets plot all of our classes F1-Scores"
      ],
      "metadata": {
        "id": "GpI6QU5f7eiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty dictionary \n",
        "class_f1_score = {}\n",
        "# Loop through classification report dictionary items\n",
        "for k, v in classification_report_dict.items():\n",
        "  if k == \"accuracy\": # Stop once we get to accuracy key\n",
        "    break\n",
        "  else:\n",
        "    # Add class names and f1-scores to new dictionary\n",
        "    class_f1_score[class_names[int(k)]] = v[\"f1-score\"]\n",
        "class_f1_score"
      ],
      "metadata": {
        "id": "G44WPvB97nyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn f1-scores into dataframe for visualization\n",
        "import pandas as pd\n",
        "f1_scores = pd.DataFrame({\"class_names\": list(class_f1_score.keys()),\n",
        "                          \"f1-score\" : list(class_f1_score.values())}).sort_values(\"f1-score\", ascending = False)"
      ],
      "metadata": {
        "id": "G4VUQH_H8bND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores"
      ],
      "metadata": {
        "id": "WSO6S0oA9M3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores[:10]"
      ],
      "metadata": {
        "id": "33cwzYpS9Nui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores[-10:]"
      ],
      "metadata": {
        "id": "4B08wnIU9QIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (12, 25))\n",
        "scores = ax.barh(range(len(f1_scores)), f1_scores[\"f1-score\"].values) #get f1-score values\n",
        "ax.set_yticks(range(len(f1_scores)))\n",
        "ax.set_yticklabels(f1_scores[\"class_names\"])\n",
        "ax.set_xlabel(\"F1-score\")\n",
        "ax.set_title(\"F1-score for 101 Different Food Classes (predicted by FoodVision Mini)\")\n",
        "ax.invert_yaxis(); # Reverse the order of our plot"
      ],
      "metadata": {
        "id": "aE5idtvY9Uca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing prediction on test images\n",
        "\n",
        "Now, this is the real test, how does our model go on food images not even in our test dataset (images of our own).\n",
        "\n",
        "To visualize our model's prediction on our own images, we'll need a function to load and preprocess images, specifically it will need to:\n",
        "* read in a target image filepath using tf.io.read_file()\n",
        "* Turn image into a Tensor using tf.io.decode_image()\n",
        "* Reshape the images tensor to be the same size as the images our model has trained on using tf.image.resize()\n",
        "* Scale the image to get all of the pixel values between 0 & 1 (if necessary)"
      ],
      "metadata": {
        "id": "adCRw2EE91DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to load and prepare images\n",
        "def load_and_prep_image(filename, img_shape = 224, scale = True):\n",
        "  \"\"\" \n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into \n",
        "  specified shape (img_shape, img_shape, color_channels = 3).\n",
        "\n",
        "  Args:\n",
        "    filename (str): path to target image\n",
        "    image_shape (int): height/width dimenstion of target image size\n",
        "    scale (bool): scale pixel values from 0-255 to 0-1 or not\n",
        "\n",
        "  Returns:\n",
        "    Image tensor of shape (img_shape, img_shape, 3)\n",
        "  \"\"\"\n",
        "\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode image into tensor\n",
        "  img = tf.io.decode_image(img, channels = 3)\n",
        "\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "\n",
        "  # Scale? yes/no\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255\n",
        "  else:\n",
        "    return img # Dont need to rescale images for EfficientNet models in TensorFlow"
      ],
      "metadata": {
        "id": "bgjAfL3ACokF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a function to load nad prepare target images, \n",
        "lets now write some code to visualize images, their target label\n",
        "and our model's predictions.\n",
        "\n",
        "Specifically, we'll write some code to:\n",
        "1. Load a few random images form the test dataset\n",
        "2. Make predictions on the loaded images\n",
        "3. Plot the original image(s) along with the model's predictions, prediction probability and truth label"
      ],
      "metadata": {
        "id": "Z9mfRnFtDQuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make preds on a series of random images\n",
        "import os\n",
        "import random\n",
        "\n",
        "plt.figure(figsize = (19, 10))\n",
        "for i in range(3):\n",
        "  # Choose a random image from a random class\n",
        "  class_name = random.choice(class_names)\n",
        "  filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n",
        "  filepath = test_dir + class_name + \"/\" + filename\n",
        "\n",
        "  # load image and make predictions\n",
        "  img = load_and_prep_image(filepath, scale = False)\n",
        "  img_expanded = tf.expand_dims(img, axis = 0)\n",
        "  pred_prob = model.predict(img_expanded) # Get prediction probabilities array\n",
        "  pred_class = class_names[pred_prob.argmax()] # Get highest probability index\n",
        "\n",
        "  # Plot the image(s)\n",
        "  plt.subplot(1, 3, i + 1)\n",
        "  plt.imshow(img/255)\n",
        "  if class_name == pred_class: # If predicted class matches truth class, make the title greem\n",
        "    title_color = \"g\"\n",
        "  else:\n",
        "    title_color = \"r\"\n",
        "  plt.title(f\"Actual: {class_name}, pred: {pred_class}, prob: {pred_prob.max():.2f}\", c = title_color)\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "fZN7FG9FFQkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most wrong predictions\n",
        "\n",
        "To find out where our model is most wrong, lets write some code to find our the following:\n",
        "1. Get all of the image file paths in the test dataset using list_files() methods\n",
        "2. Create a pandas DataFrame of the image filepaths, ground truth labels, predicted classes (from our model), max prediction probabilities, prediction class names, prediction ground truth.\n",
        "3. Use our DataFrame to find all the wrong predictions (where the ground truth label doesnt match the prediction).\n",
        "4. Sort the DataFrame based on wrong predictions (have the highest prediction probability predictions at the top).\n",
        "5. Visualize the images with the highest prediction probabilities but have the wrong prediction. "
      ],
      "metadata": {
        "id": "NK36KIVRG-ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Get all of the image file paths in the test dataset\n",
        "filepaths = []\n",
        "for filepath in test_data.list_files(\"/content/101_food_classes_10_percent/test/*/*.jpg\",\n",
        "                                     shuffle = False):\n",
        "  filepaths.append(filepath.numpy())\n",
        "filepaths[:10]"
      ],
      "metadata": {
        "id": "-ri54OtSKlQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a pandas DataFrame\n",
        "import pandas as pd\n",
        "pred_df = pd.DataFrame({\"img_path\" : filepaths,\n",
        "                        \"y_true\" : y_labels,\n",
        "                        \"y_pred\" : pred_classes,\n",
        "                        \"pred_conf\" : preds_probs.max(axis = 1), # Get the maximum prediction probabilities value\n",
        "                        \"y_true_classname\" : [class_names[i] for i in y_labels],\n",
        "                        \"y_pred_classname\" : [class_names[i] for i in pred_classes]})\n",
        "\n",
        "pred_df"
      ],
      "metadata": {
        "id": "bTsDb93KMZAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Find out in our DataFrame which predictions are wrong\n",
        "pred_df[\"pred_correct\"] = pred_df[\"y_true\"] == pred_df[\"y_pred\"]\n",
        "pred_df.head()"
      ],
      "metadata": {
        "id": "oHdl6_65NN68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Sort our DataFrame to have most wrong predictions at the top\n",
        "top_100_wrong = pred_df[pred_df[\"pred_correct\"] == False].sort_values(\"pred_conf\", ascending = False)[:100]\n",
        "top_100_wrong.head(20)"
      ],
      "metadata": {
        "id": "O4nxtqMbNnn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Visualize the test data samples which have the wrong prediction but highest pred probability\n",
        "images_to_view = 9\n",
        "start_index = 20\n",
        "plt.figure(figsize = (15, 10))\n",
        "for i, row in enumerate(top_100_wrong[start_index:start_index + images_to_view].itertuples()):\n",
        "  plt.subplot(3, 3, i + 1)\n",
        "  img = load_and_prep_image(row[1], scale = False)\n",
        "  _, _, _, _, pred_prob, y_true_classname, y_pred_classname, _ = row # Only interested in a few parameters of each row\n",
        "  plt.imshow(img/255)\n",
        "  plt.title(f\"actual: {y_true_classname}, pred: {y_pred_classname} \\nprob: {pred_prob}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "9ep_dAizOAfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test out the big dog model on our own custom images"
      ],
      "metadata": {
        "id": "xpqWO5YAPpML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get custom images\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip\n",
        "\n",
        "unzip_data(\"custom_food_images.zip\")"
      ],
      "metadata": {
        "id": "b415hO0hRFh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the custom food images filepath\n",
        "custom_food_images = [\"custom_food_images/\" + img_path for img_path in os.listdir(\"custom_food_images\")]\n",
        "custom_food_images "
      ],
      "metadata": {
        "id": "wp-dRn2RRbOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on and plot custom food images\n",
        "for img in custom_food_images:\n",
        "  img = load_and_prep_image(img, scale = False)\n",
        "  pred_prob = model.predict(tf.expand_dims(img, axis = 0))\n",
        "  pred_class = class_names[pred_prob.argmax()]\n",
        "  # Plot the appropriate information\n",
        "  plt.figure()\n",
        "  plt.imshow(img/255)\n",
        "  plt.title(f\"pred: {pred_class}, prob: {pred_prob.max():.2f}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "YN0p97e2Rqxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.6.2"
      ],
      "metadata": {
        "id": "WB2PTaoNOj6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall tensorflow-gpu"
      ],
      "metadata": {
        "id": "G2M-wEGEZmt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "BB3a2xU8ZpZT",
        "outputId": "33e4f576-2d1c-4a41-f145-7a1194db6012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2g0_6EWZ7-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}